'use client';

import { useState, useRef, useEffect, useCallback } from 'react';
import { FaceLandmarker, FilesetResolver } from '@mediapipe/tasks-vision';
import VRMViewer from '@/components/VRMViewer';
import faceParamsConfig from '@/config/face-params.json';

interface FaceFeatures {
  eyeWidth: number;
  eyeHeight: number;
  eyeAspectRatio: number;
  eyeSlantAngle: number; // ç›®ã®å‚¾æ–œè§’åº¦ï¼ˆæ­£:ã¤ã‚Šç›®ã€è² :ãŸã‚Œç›®ï¼‰
  browHeight: number; // çœ‰ã®é«˜ã•ï¼ˆç›®ã‹ã‚‰ã®è·é›¢ï¼‰
  browAngle: number; // çœ‰ã®è§’åº¦ï¼ˆæ­£:ä¸ŠãŒã‚Šçœ‰ã€è² :ä¸‹ãŒã‚Šçœ‰ï¼‰
  noseWidth: number;
  noseHeight: number;
  noseProjection: number; // é¼»ã®3Dçªå‡ºåº¦ï¼ˆzåº§æ¨™ã‚’æ´»ç”¨ï¼‰
  cheekFullness: number; // é ¬ã®ãµãã‚‰ã¿ï¼ˆè‚‰ä»˜ãï¼‰
  mouthWidth: number;
  mouthHeight: number;
  lipThickness: number; // å”‡ã®åšã¿ï¼ˆä¸Šå”‡ã¨ä¸‹å”‡ã®å¹³å‡åšã¿ï¼‰
  faceAspectRatio: number;
  jawSharpness: number; // é¡ã®å°–ã‚Šå…·åˆï¼ˆé«˜ã„å€¤ã»ã©ã‚·ãƒ£ãƒ¼ãƒ—ï¼‰
  interocularDistance: number;
  processingTime: number;
}

interface VRMAdjustments {
  eyeWide: number;
  eyeNarrow: number;
  noseWide: number;
  noseNarrow: number;
  mouthWide: number;
  mouthNarrow: number;
  faceWide: number;
  faceNarrow: number;
}

// ä»•æ§˜æ›¸æº–æ‹ : ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ­£è¦åŒ–é–¢æ•°
const normalizeParam = (value: number, paramName: string): number => {
  const config = faceParamsConfig[paramName as keyof typeof faceParamsConfig];
  if (!config) return Math.max(0, Math.min(1, value));
  
  // gain * value + offset ã®å¼ã§ 0-1 ã«å¤‰æ›
  const normalized = config.gain * value + config.offset;
  return Math.max(config.clip[0], Math.min(config.clip[1], normalized));
};

type DetectionMode = 'camera' | 'photo';

export default function FaceLandmarkTester() {
  // Refs
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const photoCanvasRef = useRef<HTMLCanvasElement>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);
  
  // Core State
  const [faceLandmarkerVideo, setFaceLandmarkerVideo] = useState<FaceLandmarker | null>(null);
  const [faceLandmarkerImage, setFaceLandmarkerImage] = useState<FaceLandmarker | null>(null);
  const [detectionMode, setDetectionMode] = useState<DetectionMode>('photo');
  const [status, setStatus] = useState('ğŸš€ AIãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...');
  const [initProgress, setInitProgress] = useState(0);
  
  // Camera State
  const [isRunning, setIsRunning] = useState(false);
  const [cameraFeatures, setCameraFeatures] = useState<FaceFeatures | null>(null);
  
  // Photo State
  const [uploadedImage, setUploadedImage] = useState<string | null>(null);
  const [photoFeatures, setPhotoFeatures] = useState<FaceFeatures | null>(null);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [analysisProgress, setAnalysisProgress] = useState(0);
  const [analysisStep, setAnalysisStep] = useState('');
  const [isWarmedUp, setIsWarmedUp] = useState(false);

  // MediaPipeåˆæœŸåŒ–
  useEffect(() => {
    const initializeMediaPipe = async () => {
      try {
        setStatus('ğŸ“¦ MediaPipe Vision Tasks ã‚’èª­ã¿è¾¼ã¿ä¸­...');
        setInitProgress(20);
        
        const vision = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
        );
        
        setStatus('ğŸ§  Face Landmarker AIãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...');
        setInitProgress(40);
        
        // VIDEOç”¨ã®FaceLandmarkerä½œæˆ
        const landmarkerVideo = await FaceLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
            delegate: "GPU"
          },
          runningMode: "VIDEO",
          numFaces: 1,
          minFaceDetectionConfidence: 0.5,
          minFacePresenceConfidence: 0.5,
          minTrackingConfidence: 0.5
        });
        
        setFaceLandmarkerVideo(landmarkerVideo);
        setInitProgress(70);
        setStatus('ğŸ“· IMAGEç”¨ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...');
        
        // IMAGEç”¨ã®FaceLandmarkerä½œæˆ
        const landmarkerImage = await FaceLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
            delegate: "GPU"
          },
          runningMode: "IMAGE",
          numFaces: 1,
          minFaceDetectionConfidence: 0.5,
          minFacePresenceConfidence: 0.5,
          minTrackingConfidence: 0.5
        });
        
        setFaceLandmarkerImage(landmarkerImage);
        setInitProgress(90);
        setStatus('ğŸ”§ MediaPipeæœ€é©åŒ–ä¸­...');
        
        // MediaPipeã®å†…éƒ¨ãƒ­ã‚°ã‚’æŠ‘åˆ¶ï¼ˆWASM/Emscriptenå‡ºåŠ›ã‚’å«ã‚€ï¼‰
        const originalConsoleLog = console.log;
        const originalConsoleInfo = console.info;
        const originalConsoleWarn = console.warn;
        const originalConsoleError = console.error;
        
        // MediaPipeã®å†…éƒ¨ãƒ­ã‚°ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        const filterMediaPipeLog = (args: unknown[]) => {
          if (args[0] && typeof args[0] === 'string') {
            const msg = args[0];
            return msg.includes('Created TensorFlow Lite XNNPACK delegate') ||
                   msg.includes('INFO:') ||
                   msg.includes('Graph successfully started') ||
                   msg.includes('Graph finished closing') ||
                   msg.includes('GL version:') ||
                   msg.includes('OpenGL error checking');
          }
          return false;
        };
        
        console.log = (...args) => {
          if (filterMediaPipeLog(args)) return;
          originalConsoleLog.apply(console, args);
        };
        console.info = (...args) => {
          if (filterMediaPipeLog(args)) return;
          originalConsoleInfo.apply(console, args);
        };
        console.warn = (...args) => {
          if (filterMediaPipeLog(args)) return;
          originalConsoleWarn.apply(console, args);
        };
        console.error = (...args) => {
          if (filterMediaPipeLog(args)) return;
          originalConsoleError.apply(console, args);
        };
        
        setIsWarmedUp(true);
        
        setInitProgress(100);
        setStatus('âœ… æº–å‚™å®Œäº†ï¼ã‚«ãƒ¡ãƒ©ã¾ãŸã¯å†™çœŸã§ãƒ†ã‚¹ãƒˆã—ã¦ãã ã•ã„');
        
      } catch (error) {
        console.error('MediaPipeåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼:', error);
        setStatus('âŒ åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚');
      }
    };

    initializeMediaPipe();
  }, []);


  // ã‚«ãƒ¡ãƒ©æ©Ÿèƒ½
  const toggleCamera = useCallback(async () => {
    if (!faceLandmarkerVideo) return;

    if (isRunning) {
      setIsRunning(false);
      if (videoRef.current?.srcObject) {
        const tracks = (videoRef.current.srcObject as MediaStream).getTracks();
        tracks.forEach(track => track.stop());
      }
      setStatus('ğŸ“¹ ã‚«ãƒ¡ãƒ©ã‚’åœæ­¢ã—ã¾ã—ãŸ');
      setCameraFeatures(null);
      return;
    }

    try {
      setDetectionMode('camera');
      setUploadedImage(null);
      setPhotoFeatures(null);
      setStatus('ğŸ“¹ ã‚«ãƒ¡ãƒ©èµ·å‹•ä¸­...');
      
      const stream = await navigator.mediaDevices.getUserMedia({ 
        video: { 
          width: { ideal: 1280, min: 640 },
          height: { ideal: 720, min: 480 },
          facingMode: 'user'
        } 
      });
      
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        videoRef.current.onloadeddata = () => {
          setIsRunning(true);
          setStatus('ğŸ¯ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é¡”æ¤œå‡ºå®Ÿè¡Œä¸­...');
          detectFaceFromVideo();
        };
      }
      
    } catch (error) {
      console.error('ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼:', error);
      setStatus('âŒ ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚HTTPSã¾ãŸã¯localhostã§ãŠè©¦ã—ãã ã•ã„ã€‚');
    }
  }, [faceLandmarkerVideo, isRunning]);

  // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é¡”æ¤œå‡º
  const detectFaceFromVideo = useCallback(() => {
    if (!videoRef.current || !canvasRef.current || !faceLandmarkerVideo || !isRunning) {
      return;
    }

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');
    
    if (!ctx) return;

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    const startTime = performance.now();
    
    try {
      // VIDEOç”¨ã®FaceLandmarkerã‚’ç›´æ¥ä½¿ç”¨
      const results = faceLandmarkerVideo.detectForVideo(video, startTime);
      const processingTime = performance.now() - startTime;

      ctx.clearRect(0, 0, canvas.width, canvas.height);

      if (results.faceLandmarks && results.faceLandmarks.length > 0) {
        const landmarks = results.faceLandmarks[0];
        drawLandmarks(ctx, landmarks, canvas.width, canvas.height);
        const calculatedFeatures = calculateDetailedFeatures(landmarks, processingTime);
        setCameraFeatures(calculatedFeatures);
      } else {
        setCameraFeatures(null);
      }
    } catch (error) {
      console.error('é¡”æ¤œå‡ºã‚¨ãƒ©ãƒ¼:', error);
    }

    if (isRunning) {
      requestAnimationFrame(detectFaceFromVideo);
    }
  }, [faceLandmarkerVideo, isRunning]);

  // å†™çœŸã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†
  const handlePhotoUpload = useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file || !faceLandmarkerImage) return;

    console.log('ğŸ” ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹:', {
      fileName: file.name,
      fileType: file.type,
      fileSize: file.size,
      lastModified: new Date(file.lastModified).toLocaleString()
    });

    // HEICå½¢å¼ã®æ¤œå‡ºã¨ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    if (file.name.toLowerCase().endsWith('.heic') || file.name.toLowerCase().endsWith('.heif')) {
      console.warn('âŒ HEIC/HEIFå½¢å¼ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“');
      alert('ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€HEIC/HEIFå½¢å¼ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚JPGã€PNGã€GIFå½¢å¼ã®ç”»åƒã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚');
      return;
    }

    if (!file.type.startsWith('image/')) {
      console.warn('âŒ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“:', file.type);
      alert('ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆJPG, PNG, GIFç­‰ï¼‰ã‚’é¸æŠã—ã¦ãã ã•ã„');
      return;
    }

    if (file.size > 10 * 1024 * 1024) {
      console.warn('âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™:', file.size);
      alert('ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™ï¼ˆ10MBä»¥ä¸‹ã«ã—ã¦ãã ã•ã„ï¼‰');
      return;
    }

    if (isRunning) {
      console.log('ğŸ“¹ ã‚«ãƒ¡ãƒ©ã‚’åœæ­¢ã—ã¦ã‹ã‚‰å†™çœŸãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆ');
      toggleCamera();
    }

    setDetectionMode('photo');
    setPhotoFeatures(null);
    setStatus('ğŸ“· å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...');

    console.log('ğŸ“ FileReaderèª­ã¿è¾¼ã¿é–‹å§‹');
    const reader = new FileReader();
    reader.onload = async (e) => {
      const imageSrc = e.target?.result as string;
      console.log('âœ… FileReaderå®Œäº†:', {
        fileType: file.type,
        fileSize: file.size,
        resultType: typeof imageSrc,
        resultLength: imageSrc?.length,
        resultPrefix: imageSrc?.substring(0, 50)
      });
      setUploadedImage(imageSrc);
      setStatus('âœ… å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚è§£æã‚’é–‹å§‹ã™ã‚‹ã«ã¯ä¸‹ã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚');

      console.log('ğŸ–¼ï¸ ç”»åƒè¦ç´ ã®èª­ã¿è¾¼ã¿é–‹å§‹');
      const img = new Image();
      img.onload = async () => {
        console.log('âœ… ç”»åƒèª­ã¿è¾¼ã¿å®Œäº†:', {
          width: img.width,
          height: img.height,
          naturalWidth: img.naturalWidth,
          naturalHeight: img.naturalHeight
        });
      };
      img.onerror = (error) => {
        console.error('âŒ ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—:', error);
        console.error('imageSrc details:', {
          length: imageSrc?.length,
          preview: imageSrc?.substring(0, 100)
        });
        setStatus('âŒ ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ');
      };
      img.src = imageSrc;
    };
    reader.onerror = (error) => {
      console.error('âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—:', error);
      setStatus('âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ');
    };
    reader.readAsDataURL(file);
  }, [faceLandmarkerImage, isRunning, toggleCamera]);

  // è§£æé–‹å§‹å‡¦ç†
  const startAnalysis = useCallback(async () => {
    if (!uploadedImage || !faceLandmarkerImage) {
      console.error('âŒ è§£æé–‹å§‹å¤±æ•—: ç”»åƒã¾ãŸã¯faceLandmarkerImageãŒã‚ã‚Šã¾ã›ã‚“', {
        hasImage: !!uploadedImage,
        hasFaceLandmarkerImage: !!faceLandmarkerImage
      });
      return;
    }
    
    console.log('ğŸš€ AIè§£æé–‹å§‹');
    setIsAnalyzing(true);
    setAnalysisProgress(0);
    setAnalysisStep('ç”»åƒæº–å‚™ä¸­...');
    setStatus('ğŸ” AIè§£æå®Ÿè¡Œä¸­...');
    
    const img = new Image();
    img.onload = async () => {
      console.log('ğŸ“¸ è§£æç”¨ç”»åƒèª­ã¿è¾¼ã¿å®Œäº†, MediaPipeå‡¦ç†é–‹å§‹');
      setAnalysisProgress(20);
      setAnalysisStep('MediaPipeå‡¦ç†é–‹å§‹...');
      await analyzePhoto(img);
    };
    img.onerror = (error) => {
      console.error('âŒ è§£æç”¨ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—:', error);
      setStatus('âŒ ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ');
      setIsAnalyzing(false);
      setAnalysisProgress(0);
      setAnalysisStep('');
    };
    img.src = uploadedImage;
  }, [uploadedImage, faceLandmarkerImage]);

  // å†™çœŸè§£æå‡¦ç†
  const analyzePhoto = useCallback(async (imageElement: HTMLImageElement) => {
    console.log('ğŸ” analyzePhotoé–¢æ•°é–‹å§‹', {
      hasFaceLandmarkerImage: !!faceLandmarkerImage,
      hasCanvas: !!photoCanvasRef.current,
      faceLandmarkerType: typeof faceLandmarkerImage,
      canvasRefType: typeof photoCanvasRef.current
    });

    if (!faceLandmarkerImage) {
      console.error('âŒ faceLandmarkerImageãŒã‚ã‚Šã¾ã›ã‚“');
      setStatus('âŒ AIè§£æãƒ¢ãƒ‡ãƒ«ï¼ˆIMAGEï¼‰ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“');
      setIsAnalyzing(false);
      return;
    }

    if (!photoCanvasRef.current) {
      console.error('âŒ photoCanvasãŒã‚ã‚Šã¾ã›ã‚“');
      setStatus('âŒ Canvasè¦ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
      setIsAnalyzing(false);
      return;
    }

    const canvas = photoCanvasRef.current;
    const ctx = canvas.getContext('2d');
    if (!ctx) {
      console.error('âŒ Canvas 2Dã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å–å¾—ã«å¤±æ•—');
      return;
    }

    try {
      console.log('ğŸ–¼ï¸ ç”»åƒå‡¦ç†é–‹å§‹:', {
        originalWidth: imageElement.width,
        originalHeight: imageElement.height,
        naturalWidth: imageElement.naturalWidth,
        naturalHeight: imageElement.naturalHeight
      });

      setAnalysisProgress(30);
      setAnalysisStep('ç”»åƒã‚µã‚¤ã‚ºèª¿æ•´ä¸­...');

      const maxWidth = 1024;
      const maxHeight = 1024;
      let { width, height } = imageElement;
      
      if (width > maxWidth || height > maxHeight) {
        const scale = Math.min(maxWidth / width, maxHeight / height);
        width *= scale;
        height *= scale;
        console.log('ğŸ“ ç”»åƒã‚µã‚¤ã‚ºèª¿æ•´:', {
          originalSize: `${imageElement.width}x${imageElement.height}`,
          scale: scale,
          newSize: `${width}x${height}`
        });
      }

      setAnalysisProgress(40);
      setAnalysisStep('Canvasæº–å‚™ä¸­...');

      canvas.width = width;
      canvas.height = height;
      ctx.drawImage(imageElement, 0, 0, width, height);
      console.log('âœ… Canvasã«ç”»åƒæç”»å®Œäº†');

      setAnalysisProgress(50);
      setAnalysisStep('MediaPipe AIè§£æå®Ÿè¡Œä¸­...');
      setStatus('ğŸ” MediaPipe AIè§£æå®Ÿè¡Œä¸­...');
      console.log('ğŸ§  MediaPipeé¡”æ¤œå‡ºå‡¦ç†é–‹å§‹');
      const startTime = performance.now();
      
      // IMAGEç”¨ã®FaceLandmarkerã‚’ç›´æ¥ä½¿ç”¨ï¼ˆãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆä¸è¦ï¼‰
      console.log('ğŸ” IMAGEç”¨FaceLandmarkerã§é¡”æ¤œå‡ºå®Ÿè¡Œä¸­...', {
        isWarmedUp,
        expectedFastProcessing: isWarmedUp
      });
      
      const results = faceLandmarkerImage.detect(imageElement);
      const processingTime = performance.now() - startTime;
      console.log('âœ… MediaPipeé¡”æ¤œå‡ºå®Œäº†', {
        processingTime: `${processingTime.toFixed(2)}ms`,
        wasWarmedUp: isWarmedUp
      });
      
      console.log('ğŸ“Š MediaPipeè§£æå®Œäº†:', {
        processingTime: `${processingTime.toFixed(2)}ms`,
        facesDetected: results.faceLandmarks?.length || 0,
        hasResults: !!(results.faceLandmarks && results.faceLandmarks.length > 0)
      });

      setAnalysisProgress(70);
      setAnalysisStep('é¡”æ¤œå‡ºçµæœå‡¦ç†ä¸­...');

      if (results.faceLandmarks && results.faceLandmarks.length > 0) {
        const landmarks = results.faceLandmarks[0];
        console.log('âœ… é¡”æ¤œå‡ºæˆåŠŸ:', {
          landmarkCount: landmarks.length,
          firstLandmark: landmarks[0],
          lastLandmark: landmarks[landmarks.length - 1]
        });
        
        setAnalysisProgress(80);
        setAnalysisStep('ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æç”»ä¸­...');
        console.log('ğŸ¨ ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æç”»é–‹å§‹');
        drawLandmarks(ctx, landmarks, width, height);
        
        setAnalysisProgress(90);
        setAnalysisStep('ç‰¹å¾´é‡è¨ˆç®—ä¸­...');
        console.log('ğŸ“ ç‰¹å¾´é‡è¨ˆç®—é–‹å§‹');
        const calculatedFeatures = calculateDetailedFeatures(landmarks, processingTime);
        console.log('âœ… ç‰¹å¾´é‡è¨ˆç®—å®Œäº†:', calculatedFeatures);
        
        setAnalysisProgress(100);
        setAnalysisStep('è§£æå®Œäº†');
        setPhotoFeatures(calculatedFeatures);
        setStatus(`âœ… é¡”æ¤œå‡ºæˆåŠŸï¼${landmarks.length}å€‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ç‚¹ã‚’æ¤œå‡º`);
      } else {
        console.warn('âŒ é¡”ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ');
        setAnalysisProgress(100);
        setAnalysisStep('é¡”æ¤œå‡ºå¤±æ•—');
        setPhotoFeatures(null);
        setStatus('âŒ é¡”ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚æ˜ã‚‹ãæ­£é¢ã‚’å‘ã„ãŸå†™çœŸã‚’ãŠè©¦ã—ãã ã•ã„ã€‚');
      }
      
    } catch (error) {
      console.error('âŒ å†™çœŸè§£æã‚¨ãƒ©ãƒ¼:', error);
      console.error('ã‚¨ãƒ©ãƒ¼è©³ç´°:', {
        name: error instanceof Error ? error.name : 'Unknown',
        message: error instanceof Error ? error.message : String(error),
        stack: error instanceof Error ? error.stack : undefined
      });
      setStatus('âŒ å†™çœŸã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ');
      setAnalysisProgress(0);
      setAnalysisStep('ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ');
    } finally {
      console.log('ğŸ è§£æå‡¦ç†å®Œäº†');
      setIsAnalyzing(false);
      setTimeout(() => {
        setAnalysisProgress(0);
        setAnalysisStep('');
      }, 2000);
    }
  }, [faceLandmarkerImage]);

  // è©³ç´°ç‰¹å¾´é‡è¨ˆç®—ï¼ˆä»•æ§˜æ›¸æº–æ‹ ï¼‰
  const calculateDetailedFeatures = (landmarks: Array<{x: number, y: number, z?: number}>, processingTime: number): FaceFeatures => {
    try {
      // ä»•æ§˜æ›¸æº–æ‹ : é¡”ã®ãƒ™ãƒ¼ã‚¹å¯¸æ³•ã‚’æœ€åˆã«è¨ˆç®—
      const faceTop = landmarks[10];       // é¡”ä¸Šç«¯
      const faceBottom = landmarks[152];   // é¡”ä¸‹ç«¯ï¼ˆé¡å…ˆï¼‰
      const faceLeft = landmarks[234];     // é¡”å·¦ç«¯
      const faceRight = landmarks[454];    // é¡”å³ç«¯
      
      const faceWidth = Math.abs(faceRight.x - faceLeft.x);
      const faceHeight = Math.abs(faceBottom.y - faceTop.y);
      const faceAspectRatio = faceHeight / faceWidth; // ä»•æ§˜æ›¸ã®faceRatioç›¸å½“

      // ç›®ã®ç‰¹å¾´ï¼ˆå·¦ç›®åŸºæº–ï¼‰
      const leftEyeOuter = landmarks[33];
      const leftEyeInner = landmarks[133];
      const leftEyeTop = landmarks[159];
      const leftEyeBottom = landmarks[145];

      // ä»•æ§˜æ›¸æº–æ‹ : ç›®ã®ç‰¹å¾´ã‚’æ­£è¦åŒ–ã—ã¦è¨ˆç®—
      const eyeWidth = Math.hypot(
        leftEyeOuter.x - leftEyeInner.x,
        leftEyeOuter.y - leftEyeInner.y
      ) / faceWidth; // æ­£è¦åŒ–

      const eyeHeight = Math.hypot(
        leftEyeTop.x - leftEyeBottom.x,
        leftEyeTop.y - leftEyeBottom.y
      ) / faceHeight; // æ­£è¦åŒ–

      const eyeAspectRatio = eyeHeight / eyeWidth;

      // ä»•æ§˜æ›¸æº–æ‹ : ç›®ã®å‚¾æ–œè§’åº¦è¨ˆç®—ï¼ˆeyeTiltï¼‰
      // æ¨å®šãƒ¬ãƒ³ã‚¸: -15Â°ï½+15Â°
      const rightEyeInner = landmarks[362];
      const eyeSlantAngle = Math.atan2(
        rightEyeInner.y - leftEyeInner.y,
        rightEyeInner.x - leftEyeInner.x
      ) * (180 / Math.PI);

      // ä¸¡ç›®ã®é–“éš”ï¼ˆæ­£è¦åŒ–ï¼‰
      const interocularDistance = Math.hypot(
        leftEyeInner.x - rightEyeInner.x,
        leftEyeInner.y - rightEyeInner.y
      ) / faceWidth; // eyeGapç›¸å½“

      // ä»•æ§˜æ›¸æº–æ‹ : çœ‰ã®ç‰¹å¾´è¨ˆç®—
      const leftBrowInner = landmarks[70];  // å·¦çœ‰å†…å´
      const leftBrowMiddle = landmarks[107]; // å·¦çœ‰ä¸­å¤®
      const leftBrowOuter = landmarks[55];  // å·¦çœ‰å¤–å´
      const rightBrowInner = landmarks[300]; // å³çœ‰å†…å´
      const rightBrowOuter = landmarks[285]; // å³çœ‰å¤–å´

      // ä»•æ§˜æ›¸æº–æ‹ : çœ‰ã®é«˜ã•ï¼ˆbrowYï¼‰- æ­£è¦åŒ–æ¸ˆã¿
      const browHeight = Math.abs(leftBrowMiddle.y - leftEyeTop.y) / faceHeight;

      // ä»•æ§˜æ›¸æº–æ‹ : çœ‰ã®è§’åº¦è¨ˆç®—ï¼ˆbrowTiltï¼‰
      // æ¨å®šãƒ¬ãƒ³ã‚¸: -20Â°ï½+20Â°
      const browAngle = Math.atan2(
        leftBrowOuter.y - leftBrowInner.y,
        leftBrowOuter.x - leftBrowInner.x
      ) * (180 / Math.PI);

      // ä»•æ§˜æ›¸æº–æ‹ : é¼»ã®ç‰¹å¾´è¨ˆç®—
      const noseLeft = landmarks[97];  // ä»•æ§˜æ›¸æ¨å¥¨ã®é¼»å·¦ç‚¹
      const noseRight = landmarks[326]; // ä»•æ§˜æ›¸æ¨å¥¨ã®é¼»å³ç‚¹
      const noseTip = landmarks[1];
      const noseBridge = landmarks[168]; // ä»•æ§˜æ›¸æ¨å¥¨ã®é¼»æ ¹ç‚¹

      // æ­£è¦åŒ–æ¸ˆã¿é¼»ã®ç‰¹å¾´
      const noseWidth = Math.hypot(
        noseLeft.x - noseRight.x,
        noseLeft.y - noseRight.y
      ) / faceWidth; // æ¨å®šãƒ¬ãƒ³ã‚¸: 0.12-0.25

      const noseHeight = Math.hypot(
        noseBridge.x - noseTip.x,
        noseBridge.y - noseTip.y
      ) / faceHeight; // noseLengthç›¸å½“

      // ä»•æ§˜æ›¸æº–æ‹ : zåº§æ¨™ã‚’æ´»ç”¨ã—ãŸ3Dçªå‡ºåº¦
      const noseProjection = noseTip.z ? Math.abs(noseTip.z) : 0;

      // ä»•æ§˜æ›¸æº–æ‹ : é ¬ã®ãµãã‚‰ã¿è¨ˆç®—ï¼ˆæ­£è¦åŒ–ï¼‰
      const leftCheek = landmarks[234];   // å·¦é ¬ã®æœ€å¤–å´
      const rightCheek = landmarks[454];  // å³é ¬ã®æœ€å¤–å´  
      const faceLeftEdge = landmarks[172]; // é¡”ã®å·¦ç«¯ï¼ˆé¡è§’ä»˜è¿‘ï¼‰
      const faceRightEdge = landmarks[397]; // é¡”ã®å³ç«¯ï¼ˆé¡è§’ä»˜è¿‘ï¼‰
      
      // æ­£è¦åŒ–æ¸ˆã¿é ¬ã®è†¨ã‚‰ã¿
      const leftCheekFullness = Math.hypot(
        leftCheek.x - faceLeftEdge.x,
        leftCheek.y - faceLeftEdge.y
      ) / faceWidth;
      const rightCheekFullness = Math.hypot(
        rightCheek.x - faceRightEdge.x,
        rightCheek.y - faceRightEdge.y
      ) / faceWidth;
      const cheekFullness = (leftCheekFullness + rightCheekFullness) / 2;

      // ä»•æ§˜æ›¸æº–æ‹ : å£ã®ç‰¹å¾´è¨ˆç®—
      const mouthLeft = landmarks[61];
      const mouthRight = landmarks[291];
      const mouthTop = landmarks[13];
      const mouthBottom = landmarks[14];

      // æ­£è¦åŒ–æ¸ˆã¿å£ã®ç‰¹å¾´
      const mouthWidth = Math.hypot(
        mouthLeft.x - mouthRight.x,
        mouthLeft.y - mouthRight.y
      ) / faceWidth; // æ¨å®šãƒ¬ãƒ³ã‚¸: 0.25-0.50

      const mouthHeight = Math.hypot(
        mouthTop.x - mouthBottom.x,
        mouthTop.y - mouthBottom.y
      ) / faceHeight;

      // ä»•æ§˜æ›¸æº–æ‹ : å”‡ã®åšã¿è¨ˆç®—ï¼ˆæ­£è¦åŒ–ï¼‰
      const upperLipTop = landmarks[13];    // ä¸Šå”‡ã®ä¸Šç«¯
      const upperLipBottom = landmarks[12]; // ä¸Šå”‡ã®ä¸‹ç«¯ï¼ˆå”‡ã®å¢ƒç•Œç·šï¼‰
      const lowerLipTop = landmarks[15];    // ä¸‹å”‡ã®ä¸Šç«¯ï¼ˆå”‡ã®å¢ƒç•Œç·šï¼‰
      const lowerLipBottom = landmarks[17]; // ä¸‹å”‡ã®ä¸‹ç«¯
      
      // æ­£è¦åŒ–æ¸ˆã¿å”‡ã®åšã¿
      const upperLipThickness = Math.hypot(
        upperLipTop.x - upperLipBottom.x,
        upperLipTop.y - upperLipBottom.y
      ) / faceHeight;
      
      const lowerLipThickness = Math.hypot(
        lowerLipTop.x - lowerLipBottom.x,
        lowerLipTop.y - lowerLipBottom.y
      ) / faceHeight;
      
      // æ¨å®šãƒ¬ãƒ³ã‚¸: 0.01-0.04
      const lipThickness = (upperLipThickness + lowerLipThickness) / 2;

      // ä»•æ§˜æ›¸æº–æ‹ : é¡ã®è§’åº¦è¨ˆç®—ï¼ˆjawAngleï¼‰
      // æ¨å®šãƒ¬ãƒ³ã‚¸: 60-120Â°
      const chinTip = landmarks[152]; // é¡å…ˆï¼ˆä»•æ§˜æ›¸æº–æ‹ ï¼‰
      const leftJaw = landmarks[234];  // å·¦é¡è§’
      const rightJaw = landmarks[454]; // å³é¡è§’
      
      // é¡ã®è§’åº¦ã‚’è¨ˆç®—ï¼ˆâˆ (LM234-LM152-LM454)ï¼‰
      const leftJawVector = {
        x: leftJaw.x - chinTip.x,
        y: leftJaw.y - chinTip.y
      };
      const rightJawVector = {
        x: rightJaw.x - chinTip.x,
        y: rightJaw.y - chinTip.y
      };
      
      // ä¸¡ãƒ™ã‚¯ãƒˆãƒ«ã®å†…ç©ã‹ã‚‰è§’åº¦ã‚’è¨ˆç®—
      const dotProduct = leftJawVector.x * rightJawVector.x + leftJawVector.y * rightJawVector.y;
      const leftMagnitude = Math.hypot(leftJawVector.x, leftJawVector.y);
      const rightMagnitude = Math.hypot(rightJawVector.x, rightJawVector.y);
      const jawAngle = Math.acos(dotProduct / (leftMagnitude * rightMagnitude)) * (180 / Math.PI);
      
      // ä»•æ§˜æ›¸æº–æ‹ : è§’åº¦ã‚’Sharp/Roundåˆ¤å®šã«å¤‰æ›
      const jawSharpness = jawAngle < 90 ? (90 - jawAngle) / 30 : 0; // 0-1å€¤

      return {
        eyeWidth: Number(eyeWidth.toFixed(4)),
        eyeHeight: Number(eyeHeight.toFixed(4)),
        eyeAspectRatio: Number(eyeAspectRatio.toFixed(4)),
        eyeSlantAngle: Number(eyeSlantAngle.toFixed(2)),
        browHeight: Number(browHeight.toFixed(4)),
        browAngle: Number(browAngle.toFixed(2)),
        noseWidth: Number(noseWidth.toFixed(4)),
        noseHeight: Number(noseHeight.toFixed(4)),
        noseProjection: Number(noseProjection.toFixed(4)),
        cheekFullness: Number(cheekFullness.toFixed(4)),
        mouthWidth: Number(mouthWidth.toFixed(4)),
        mouthHeight: Number(mouthHeight.toFixed(4)),
        lipThickness: Number(lipThickness.toFixed(4)),
        faceAspectRatio: Number(faceAspectRatio.toFixed(4)),
        jawSharpness: Number(jawSharpness.toFixed(3)),
        interocularDistance: Number(interocularDistance.toFixed(4)),
        processingTime: Number(processingTime.toFixed(2))
      };
    } catch (error) {
      console.error('ç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼:', error);
      return {
        eyeWidth: 0, eyeHeight: 0, eyeAspectRatio: 0, eyeSlantAngle: 0, browHeight: 0, browAngle: 0,
        noseWidth: 0, noseHeight: 0, noseProjection: 0, cheekFullness: 0, mouthWidth: 0, mouthHeight: 0, lipThickness: 0,
        faceAspectRatio: 0, jawSharpness: 0, interocularDistance: 0,
        processingTime: Number(processingTime.toFixed(2))
      };
    }
  };

  // VRMèª¿æ•´äºˆæ¸¬è¨ˆç®—
  const predictVRMAdjustments = (features: FaceFeatures): VRMAdjustments => {
    const baseline = {
      eyeAspectRatio: 0.25,
      noseWidth: 0.04,
      mouthWidth: 0.06,
      faceAspectRatio: 1.3
    };

    const adjustments: VRMAdjustments = {
      eyeWide: 0, eyeNarrow: 0, noseWide: 0, noseNarrow: 0,
      mouthWide: 0, mouthNarrow: 0, faceWide: 0, faceNarrow: 0
    };

    try {
      const eyeRatio = features.eyeAspectRatio / baseline.eyeAspectRatio;
      if (eyeRatio > 1.2) {
        adjustments.eyeWide = Math.min((eyeRatio - 1) * 2, 1.0);
      } else if (eyeRatio < 0.8) {
        adjustments.eyeNarrow = Math.min((1 - eyeRatio) * 2, 1.0);
      }

      const noseRatio = features.noseWidth / baseline.noseWidth;
      if (noseRatio > 1.15) {
        adjustments.noseWide = Math.min((noseRatio - 1) * 1.5, 1.0);
      } else if (noseRatio < 0.85) {
        adjustments.noseNarrow = Math.min((1 - noseRatio) * 1.5, 1.0);
      }

      const mouthRatio = features.mouthWidth / baseline.mouthWidth;
      if (mouthRatio > 1.1) {
        adjustments.mouthWide = Math.min((mouthRatio - 1) * 1.5, 1.0);
      } else if (mouthRatio < 0.9) {
        adjustments.mouthNarrow = Math.min((1 - mouthRatio) * 1.5, 1.0);
      }

      const faceRatio = features.faceAspectRatio / baseline.faceAspectRatio;
      if (faceRatio > 1.1) {
        adjustments.faceNarrow = Math.min((faceRatio - 1) * 1.2, 1.0);
      } else if (faceRatio < 0.9) {
        adjustments.faceWide = Math.min((1 - faceRatio) * 1.2, 1.0);
      }
    } catch (error) {
      console.error('VRMèª¿æ•´è¨ˆç®—ã‚¨ãƒ©ãƒ¼:', error);
    }

    return adjustments;
  };

  // ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æç”»é–¢æ•°
  const drawLandmarks = (ctx: CanvasRenderingContext2D, landmarks: Array<{x: number, y: number, z?: number}>, width: number, height: number) => {
    ctx.lineWidth = 2;
    ctx.globalAlpha = 0.8;

    const faceOval = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109];
    const leftEye = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246];
    const rightEye = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398];
    const lips = [61, 84, 17, 314, 405, 320, 307, 375, 321, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95];
    const nose = [1, 2, 5, 4, 6, 168, 8, 9, 10, 151, 195, 197, 196, 3, 51, 48, 115, 131, 134, 102, 49, 220, 305, 290, 328, 326];

    [
      { points: faceOval, color: '#00FF00' },
      { points: leftEye, color: '#FF3333' },
      { points: rightEye, color: '#FF3333' },
      { points: lips, color: '#3333FF' },
      { points: nose, color: '#FFFF33' }
    ].forEach(({ points, color }) => {
      ctx.fillStyle = color;
      points.forEach((index) => {
        if (landmarks[index]) {
          const x = landmarks[index].x * width;
          const y = landmarks[index].y * height;
          ctx.beginPath();
          ctx.arc(x, y, 2, 0, 2 * Math.PI);
          ctx.fill();
        }
      });
    });

    ctx.globalAlpha = 1.0;
  };

  return (
    <div className="max-w-7xl mx-auto p-6 bg-gray-50 min-h-screen">
      <div className="text-center mb-8">
        <h1 className="text-4xl font-bold mb-4 bg-gradient-to-r from-blue-600 to-purple-600 bg-clip-text text-transparent">
          MediaPipe Face Landmarks
        </h1>
        <h2 className="text-2xl font-semibold text-gray-700">
          ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¨¼ãƒ†ã‚¹ãƒˆã‚¢ãƒ—ãƒª
        </h2>
      </div>

      {/* åˆæœŸåŒ–ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ */}
      {initProgress < 100 && (
        <div className="max-w-md mx-auto mb-8">
          <div className="bg-white rounded-lg p-6 shadow-lg">
            <div className="text-center mb-4">
              <div className="text-lg font-semibold text-gray-700">{status}</div>
            </div>
            <div className="w-full bg-gray-200 rounded-full h-3">
              <div 
                className="bg-blue-500 h-3 rounded-full transition-all duration-300"
                style={{ width: `${initProgress}%` }}
              ></div>
            </div>
            <div className="text-center mt-2 text-sm text-gray-600">
              {initProgress}%
            </div>
          </div>
        </div>
      )}

      {faceLandmarkerVideo && faceLandmarkerImage && (
        <>
          <div className="text-center mb-8">
            <div className={`inline-block px-6 py-3 rounded-full text-lg font-semibold ${
              status.includes('âŒ') ? 'bg-red-100 text-red-700' : 
              status.includes('âœ…') ? 'bg-green-100 text-green-700' : 
              'bg-blue-100 text-blue-700'
            }`}>
              {status}
            </div>
          </div>

          {/* ãƒ¢ãƒ¼ãƒ‰é¸æŠã‚¿ãƒ– */}
          <div className="flex justify-center mb-8">
            <div className="bg-white rounded-xl p-1 shadow-lg">
              <button
                onClick={() => setDetectionMode('photo')}
                className={`px-8 py-3 rounded-lg font-semibold transition-all duration-200 ${
                  detectionMode === 'photo'
                    ? 'bg-green-500 text-white shadow-lg transform scale-105'
                    : 'text-gray-700 hover:bg-gray-100'
                }`}
              >
                ğŸ“· å†™çœŸã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆæ¨å¥¨ï¼‰
              </button>
              <button
                onClick={() => setDetectionMode('camera')}
                className={`px-8 py-3 rounded-lg font-semibold transition-all duration-200 ${
                  detectionMode === 'camera'
                    ? 'bg-blue-500 text-white shadow-lg transform scale-105'
                    : 'text-gray-700 hover:bg-gray-100'
                }`}
              >
                ğŸ“¹ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚«ãƒ¡ãƒ©
              </button>
            </div>
          </div>

          {/* å†™çœŸã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ¢ãƒ¼ãƒ‰ */}
          {detectionMode === 'photo' && (
            <div className="mb-8">
              <div className="text-center mb-6">
                <input
                  ref={fileInputRef}
                  type="file"
                  accept="image/jpeg,image/jpg,image/png,image/gif,image/webp"
                  onChange={handlePhotoUpload}
                  className="hidden"
                />
                <button
                  onClick={() => fileInputRef.current?.click()}
                  disabled={!faceLandmarkerImage || isAnalyzing}
                  className="px-10 py-4 bg-green-500 hover:bg-green-600 disabled:bg-gray-400 text-white rounded-xl font-bold text-lg disabled:cursor-not-allowed transform hover:scale-105 transition-all duration-200 shadow-lg"
                >
                  {isAnalyzing ? 'ğŸ”„ è§£æä¸­...' : 'ğŸ“ å†™çœŸã‚’é¸æŠã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰'}
                </button>
                <p className="text-sm text-gray-600 mt-2">
                  JPG, PNG, GIF, WebPå¯¾å¿œ / æœ€å¤§10MB (HEIC/HEIFéå¯¾å¿œ)
                </p>
              </div>

              {uploadedImage && (
                <div className="flex justify-center mb-6">
                  <div className="relative max-w-4xl">
                    {!photoFeatures && (
                      <div className="relative">
                        <img
                          src={uploadedImage}
                          alt="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ"
                          className="border-4 border-gray-300 rounded-lg shadow-xl max-w-full h-auto"
                          style={{ maxHeight: '600px' }}
                        />
                        {!isAnalyzing && (
                          <div className="absolute bottom-4 left-1/2 transform -translate-x-1/2">
                            <button
                              onClick={() => startAnalysis()}
                              className="bg-green-500 hover:bg-green-600 text-white px-6 py-3 rounded-lg font-semibold shadow-lg transition-all duration-200 transform hover:scale-105"
                            >
                              ğŸ” é¡”è§£æã‚’é–‹å§‹
                            </button>
                          </div>
                        )}
                        {isAnalyzing && (
                          <div className="absolute inset-0 bg-black bg-opacity-20 rounded-lg flex items-center justify-center">
                            <div className="bg-white bg-opacity-95 px-6 py-4 rounded-lg text-gray-700 font-semibold max-w-sm w-full mx-4">
                              <div className="text-center mb-3">
                                <div className="text-lg mb-1">ğŸ”„ è§£æä¸­...</div>
                                <div className="text-sm text-gray-600">{analysisStep}</div>
                              </div>
                              <div className="w-full bg-gray-200 rounded-full h-3">
                                <div 
                                  className="bg-blue-500 h-3 rounded-full transition-all duration-300"
                                  style={{ width: `${analysisProgress}%` }}
                                ></div>
                              </div>
                              <div className="text-center mt-2 text-sm text-gray-600">
                                {analysisProgress}%
                              </div>
                            </div>
                          </div>
                        )}
                      </div>
                    )}
                    {(photoFeatures || isAnalyzing) && (
                      <canvas
                        ref={photoCanvasRef}
                        className="border-4 border-green-300 rounded-lg shadow-xl max-w-full h-auto"
                        style={{ display: photoFeatures ? 'block' : 'none' }}
                      />
                    )}
                  </div>
                </div>
              )}
            </div>
          )}

          {/* ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰ */}
          {detectionMode === 'camera' && (
            <div className="mb-8">
              <div className="flex justify-center mb-6">
                <div className="relative">
                  <video
                    ref={videoRef}
                    className="absolute inset-0 w-full h-full object-cover rounded-lg"
                    autoPlay
                    playsInline
                    muted
                  />
                  <canvas
                    ref={canvasRef}
                    className="relative z-10 border-4 border-blue-300 rounded-lg shadow-xl"
                    width={640}
                    height={480}
                  />
                </div>
              </div>

              <div className="text-center">
                <button
                  onClick={toggleCamera}
                  disabled={!faceLandmarkerVideo}
                  className={`px-10 py-4 rounded-xl font-bold text-lg transition-all duration-200 ${
                    isRunning 
                      ? 'bg-red-500 hover:bg-red-600 text-white shadow-lg' 
                      : 'bg-blue-500 hover:bg-blue-600 text-white shadow-lg'
                  } disabled:bg-gray-400 disabled:cursor-not-allowed transform hover:scale-105`}
                >
                  {isRunning ? 'ğŸ›‘ ã‚«ãƒ¡ãƒ©åœæ­¢' : 'ğŸ¬ ã‚«ãƒ¡ãƒ©èµ·å‹•'}
                </button>
              </div>
            </div>
          )}

          {/* æ¤œå‡ºçµæœè¡¨ç¤º */}
          {((detectionMode === 'camera' && cameraFeatures) || (detectionMode === 'photo' && photoFeatures)) && (
            <>
              <div className="bg-white rounded-2xl p-8 mb-8 shadow-xl">
                <h2 className="text-2xl font-bold mb-6 text-center text-gray-800">ğŸ¯ æ¤œå‡ºã•ã‚ŒãŸé¡”ç‰¹å¾´é‡</h2>
              
              {(() => {
                const currentFeatures = detectionMode === 'camera' ? cameraFeatures : photoFeatures;
                const adjustments = currentFeatures ? predictVRMAdjustments(currentFeatures) : null;
                
                return (
                  <>
                    {/* ç‰¹å¾´é‡ã‚°ãƒªãƒƒãƒ‰ */}
                    <div className="grid grid-cols-2 md:grid-cols-3 lg:grid-cols-4 gap-4 mb-8">
                      {[
                        { label: 'é¡”ã®ç¸¦æ¨ªæ¯”', param: 'faceRatio', value: currentFeatures?.faceAspectRatio, color: 'purple' },
                        { label: 'ç›®ã®å‚¾æ–œè§’åº¦', param: 'eyeTilt', value: currentFeatures?.eyeSlantAngle, unit: 'Â°', color: 'blue' },
                        { label: 'çœ‰ã®è§’åº¦', param: 'browTilt', value: currentFeatures?.browAngle, unit: 'Â°', color: 'blue' },
                        { label: 'çœ‰ã®é«˜ã•', param: 'browY', value: currentFeatures?.browHeight, color: 'blue' },
                        { label: 'ä¸¡ç›®ã®é–“éš”', param: 'eyeGap', value: currentFeatures?.interocularDistance, color: 'orange' },
                        { label: 'é¼»ã®å¹…', param: 'noseWidth', value: currentFeatures?.noseWidth, color: 'green' },
                        { label: 'é¼»ã®é«˜ã•', param: 'noseLength', value: currentFeatures?.noseHeight, color: 'green' },
                        { label: 'å£ã®å¹…', param: 'mouthWidth', value: currentFeatures?.mouthWidth, color: 'red' },
                        { label: 'å”‡ã®åšã¿', param: 'lipThick', value: currentFeatures?.lipThickness, color: 'red' },
                        { label: 'é¡ã®å°–ã‚Šå…·åˆ', param: 'jawAngle', value: currentFeatures?.jawSharpness, color: 'purple' },
                        { label: 'é¼»ã®çªå‡ºåº¦', value: currentFeatures?.noseProjection, color: 'green' },
                        { label: 'é ¬ã®ãµãã‚‰ã¿', value: currentFeatures?.cheekFullness, color: 'orange' },
                        { label: 'å‡¦ç†æ™‚é–“', value: `${currentFeatures?.processingTime}ms`, color: 'gray' }
                      ].map((item, index) => {
                        const rawValue = typeof item.value === 'number' ? item.value : 0;
                        const morphValue = item.param ? normalizeParam(rawValue, item.param) : null;
                        
                        return (
                          <div key={index} className="bg-white p-3 rounded-xl shadow-md hover:shadow-lg transition-shadow border-2 border-gray-200">
                            <h3 className={`font-semibold text-${item.color}-600 text-xs mb-1`}>{item.label}</h3>
                            <div className="space-y-1">
                              <p className="text-sm font-mono text-gray-800">
                                {typeof item.value === 'number' ? 
                                  `${item.value.toFixed(4)}${item.unit || ''}` : 
                                  item.value
                                }
                              </p>
                              {morphValue !== null && (
                                <p className="text-xs font-bold text-blue-600">
                                  morph: {(morphValue * 100).toFixed(0)}%
                                </p>
                              )}
                            </div>
                          </div>
                        );
                      })}
                    </div>

                    {/* VRMèª¿æ•´äºˆæ¸¬ */}
                    {adjustments && (
                      <div className="bg-gradient-to-r from-blue-50 to-purple-50 rounded-xl p-6 border-2 border-blue-200">
                        <h3 className="font-bold text-blue-800 mb-4 text-xl flex items-center">
                          ğŸ­ VRM BlendShapeèª¿æ•´äºˆæ¸¬
                        </h3>
                        <div className="grid grid-cols-2 md:grid-cols-4 gap-4 mb-4">
                          {Object.entries(adjustments).map(([key, value]) => (
                            value > 0.01 && (
                              <div key={key} className="bg-white p-4 rounded-lg shadow-sm border-l-4 border-blue-400">
                                <div className="font-semibold text-blue-700 text-sm mb-1">{key}</div>
                                <div className="text-xl font-bold text-blue-900 mb-2">
                                  {(value * 100).toFixed(0)}%
                                </div>
                                <div className="w-full bg-gray-200 rounded-full h-2">
                                  <div 
                                    className="bg-blue-500 h-2 rounded-full transition-all duration-300"
                                    style={{ width: `${value * 100}%` }}
                                  ></div>
                                </div>
                              </div>
                            )
                          ))}
                        </div>
                        <div className="bg-blue-100 p-4 rounded-lg">
                          <p className="text-sm text-blue-700">
                            <strong>ğŸ’¡ VRMèª¿æ•´ã¸ã®æ´»ç”¨:</strong> 
                            ä¸Šè¨˜ã®æ•°å€¤ã‚’VRMãƒ•ã‚¡ã‚¤ãƒ«ã®BlendShapeã«é©ç”¨ã™ã‚‹ã“ã¨ã§ã€
                            å†™çœŸã®äººç‰©ã«ä¼¼ãŸã‚¢ãƒã‚¿ãƒ¼ã‚’è‡ªå‹•ç”Ÿæˆã§ãã¾ã™ã€‚
                          </p>
                        </div>
                      </div>
                    )}
                  </>
                );
              })()}
              </div>

              {/* VRMãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ */}
              <div className="bg-white rounded-2xl p-8 mb-8 shadow-xl">
                <h2 className="text-2xl font-bold mb-6 text-center text-gray-800">
                  ğŸ­ VRM ã‚¢ãƒã‚¿ãƒ¼ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                </h2>
                <div className="bg-gray-50 rounded-xl p-4 mb-4">
                  <p className="text-center text-gray-600 mb-2">
                    é¡”ç‰¹å¾´é‡ã«åŸºã¥ã„ã¦VRMã‚¢ãƒã‚¿ãƒ¼ãŒè‡ªå‹•èª¿æ•´ã•ã‚Œã¾ã™
                  </p>
                </div>
                <div style={{ height: '500px' }}>
                  <VRMViewer 
                    faceFeatures={detectionMode === 'camera' ? cameraFeatures : photoFeatures}
                  />
                </div>
              </div>
            </>
          )}

          {/* ä½¿ç”¨æ–¹æ³•ãƒ»æ³¨æ„äº‹é … */}
          <div className="bg-yellow-50 border-2 border-yellow-200 rounded-xl p-6">
            <h3 className="font-bold text-yellow-800 mb-4 text-xl">
              ğŸ“‹ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆæ™‚ã®é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ
            </h3>
            <div className="bg-blue-50 border border-blue-200 rounded-lg p-4 mb-4">
              <h4 className="font-bold text-blue-700 mb-2">
                ğŸ’¡ é–‹ç™ºè€…ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ã¤ã„ã¦
              </h4>
              <p className="text-sm text-blue-700">
                ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤ºã•ã‚Œã‚‹ã€ŒINFO: Created TensorFlow Lite XNNPACK delegate for CPUã€ã‚„
                ã€ŒGraph successfully started runningã€ãªã©ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ã€MediaPipeã®æ­£å¸¸ãªå‹•ä½œãƒ­ã‚°ã§ã™ã€‚
                ã‚¨ãƒ©ãƒ¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã®ã§ã”å®‰å¿ƒãã ã•ã„ã€‚
              </p>
            </div>
            <div className="grid md:grid-cols-2 gap-6">
              <div className="bg-white p-4 rounded-lg">
                <h4 className="font-bold text-green-700 mb-2">
                  ğŸ“· å†™çœŸãƒ¢ãƒ¼ãƒ‰ï¼ˆæ¨å¥¨ï¼‰
                </h4>
                <ul className="text-sm text-gray-700 space-y-1">
                  <li>â€¢ é«˜ç²¾åº¦ãªç‰¹å¾´é‡æ¸¬å®šãŒå¯èƒ½</li>
                  <li>â€¢ VRMèª¿æ•´äºˆæ¸¬ã®è©³ç´°ç¢ºèª</li>
                  <li>â€¢ HTTPç’°å¢ƒã§ã‚‚å‹•ä½œ</li>
                  <li>â€¢ æ§˜ã€…ãªäººç‰©ã§ã®æ¯”è¼ƒãƒ†ã‚¹ãƒˆ</li>
                  <li>â€¢ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: æœ€å¤§10MB</li>
                </ul>
              </div>
              <div className="bg-white p-4 rounded-lg">
                <h4 className="font-bold text-blue-700 mb-2">
                  ğŸ“¹ ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰
                </h4>
                <ul className="text-sm text-gray-700 space-y-1">
                  <li>â€¢ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã®æ•°å€¤å¤‰åŒ–ç¢ºèª</li>
                  <li>â€¢ è¡¨æƒ…ãƒ»è§’åº¦å¤‰åŒ–ã®ãƒ†ã‚¹ãƒˆ</li>
                  <li>â€¢ localhostç’°å¢ƒã§ã‚‚å‹•ä½œå¯èƒ½</li>
                  <li>â€¢ ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚«ãƒ¡ãƒ©è¨±å¯ãŒå¿…è¦</li>
                  <li>â€¢ å‡¦ç†é€Ÿåº¦ãƒ»å®‰å®šæ€§ã®è©•ä¾¡</li>
                </ul>
              </div>
            </div>
          </div>
        </>
      )}
    </div>
  );
}
